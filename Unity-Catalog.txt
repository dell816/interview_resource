
Adaptive Query Execution in Spark

Adaptive Query Execution (AQE) is an advanced optimization technique in Apache Spark SQL that dynamically adjusts query execution plans during runtime based on accurate runtime statistics. This feature, introduced in Spark 3.0 and enabled by default since Spark 3.2, addresses inefficiencies caused by static query planning, such as outdated or inaccurate statistics, data skew, and suboptimal partitioning.

Key Features of AQE

Dynamic Partition Coalescing: AQE combines small shuffle partitions into larger ones during runtime to reduce overhead from scheduling and task setup. This improves I/O throughput and cluster resource utilization.

Dynamic Join Strategy Switching: Based on runtime statistics, AQE can switch from a sort-merge join to a broadcast hash join if one side of the join is small enough to fit in memory. This reduces shuffle and network overhead.

Skew Join Optimization: AQE detects data skew in partitions and splits skewed partitions into smaller sub partitions. This ensures balanced task execution and avoids straggler tasks that slow down query performance.

Empty Relation Propagation: AQE dynamically detects and eliminates empty relations during query execution, optimizing resource usage and reducing unnecessary computations.

How AQE Works

AQE operates by breaking queries into query stages, which are sections of the query plan separated by shuffle or broadcast exchanges. After each stage completes, AQE collects runtime statistics and re-optimizes the remaining query plan. This iterative process continues until the entire query is executed.

For example:

If runtime statistics reveal that a join relation is smaller than expected, AQE may switch to a broadcast join.

If shuffle partitions are unevenly distributed, AQE adjusts partition sizes to balance workloads.


Two main techniques to solve data skew in Apache Spark:

Adaptive Query Execution (AQE) and Broadcast Joins.

Adaptive Query Execution (AQE) (0:35)

AQE, introduced in Spark 3.0, uses runtime statistics to select the most efficient query plan dynamically (0:45).
It provides three main optimizations:
   1- Tuning shuffle partitions: Coalesces partitions to reduce the number of empty or unnecessary shuffle  	partitions, thus reducing overhead (1:21).
   2-Optimizing joins: Converts sort-merge joins into broadcast joins for better performance, as broadcast joins do 	not involve costly data shuffling across the network (2:15).
   3-Optimizing skewed joins: Breaks down large, skewed partitions in sort-merge joins into smaller, more 	manageable partitions (2:50).
To enable AQE for skewed joins, specific Spark SQL properties (spark.sql.adaptive.enabled and spark.sql.adaptive.skewJoin.enabled) must be set to true (3:42).



Broadcast joins are considered more efficient than sort-merge joins when one of the tables is significantly smaller than the other (10:56).
Sort-Merge Join Internal Working (11:18): Involves three costly steps: shuffle (data transfer over the network), sort, and merge. Data is partitioned based on a hash of the join key modulo the number of shuffle partitions (13:12).
Broadcast Join Internal Working (17:12): The smaller dataset is broadcast (sent) to all executors, eliminating the need for shuffling the larger dataset. This makes broadcast joins immune to skewed input data because partitioning of the larger table can be done independently of the join keys, ensuring even distribution (18:18).

